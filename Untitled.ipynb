{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7018e9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import ColorMode, Visualizer\n",
    "from detectron2 import model_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fea933ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b20a554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instance Segmentation\n",
    "cfg = get_cfg()\n",
    "\n",
    "# Load the model config and pre-trained model\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "cfg.MODEL.DEVICE = \"cpu\" #\"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5789d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e332425c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"General_public_preview.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0659bbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# while sucess:\n",
    "#     print(f\"{cap.get(1)}/{cap.get(cv2.CAP_PROP_FRAME_COUNT)}\")\n",
    "#     predictions = predictor(image)\n",
    "\n",
    "#     viz = Visualizer(image[:,:,::-1], \n",
    "#                     metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]),\n",
    "#                     instance_mode = ColorMode.IMAGE\n",
    "#                     )\n",
    "\n",
    "#     output = viz.draw_instance_predictions(predictions['instances'].to(\"cpu\"))\n",
    "\n",
    "\n",
    "#     cv2.imshow('Results', output.get_image()[:,:,::-1])\n",
    "\n",
    "#     key = cv2.waitKey(1) & 0xFF\n",
    "#     if key==ord(\"q\"):\n",
    "#         break\n",
    "#     (sucess, image) =  cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "088f3d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils.video import FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f8a0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0/608.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Computer_Vision\\lib\\site-packages\\torch\\functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\TensorShape.cpp:3484.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0/608.0\n",
      "3.0/608.0\n",
      "4.0/608.0\n",
      "5.0/608.0\n",
      "6.0/608.0\n",
      "7.0/608.0\n",
      "8.0/608.0\n",
      "9.0/608.0\n",
      "10.0/608.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'NoneType' and 'datetime.datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22088\\3445022481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mfps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Elasped time: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melapsed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FPS: {:.2f}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Computer_Vision\\lib\\site-packages\\imutils\\video\\fps.py\u001b[0m in \u001b[0;36melapsed\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m# return the total number of seconds between the start and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m# end interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_end\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'NoneType' and 'datetime.datetime'"
     ]
    }
   ],
   "source": [
    "fps = FPS().start()\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print(f\"{cap.get(1)}/{cap.get(cv2.CAP_PROP_FRAME_COUNT)}\")\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Perform object detection with Detectron2\n",
    "    outputs = detector(frame)\n",
    "\n",
    "    # Get boxes, classes, and scores from the detection results\n",
    "    boxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "    scores = outputs[\"instances\"].scores.cpu().numpy()\n",
    "\n",
    "    # Loop through detected objects and overlay bounding boxes\n",
    "    for box, class_id, score in zip(boxes, classes, scores):\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        class_name = MetadataCatalog.get(cfg.DATASETS.TRAIN[0]).thing_classes[class_id]\n",
    "        label = f\"{class_name}: {score:.2f}\"\n",
    "        color = (0, 255, 0)  # Green color\n",
    "        thickness = 2\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), color, thickness)\n",
    "        cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, thickness)\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Detectron2 Video', frame)\n",
    "    \n",
    "    fps.update()\n",
    "    \n",
    "    # Check for user interrupt (press 'q' to exit)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "fps.stop()\n",
    "print(\"Elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "print(\"FPS: {:.2f}\".format(fps.fps()))\n",
    "    \n",
    "# Release the video objects\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011c648",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
